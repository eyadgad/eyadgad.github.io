<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="ikcofzeorx0zE-BrA8H5X2-9FHoKtjo7bNyLCGncTa8"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Research | EYAD GAD </title> <meta name="author" content="EYAD GAD"> <meta name="description" content="This is Eyad Gad's website, a portfolio of my work in computer science and engineering. "> <meta name="keywords" content="eyad-gad, gad, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?0c57b1946a643d1007619f41bcdea224"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://eyadgad.github.io/research/"> <script src="/assets/js/theme.js?05b5399889a5a42c8433323643b810b7"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <div class="fireflies-container"> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> <div class="firefly"></div> </div> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter watermelon-name-nav" href="/"> <span class="letter">E</span><span class="letter">Y</span> <svg class="watermelon-a" viewbox="0 0 100 100" role="img" aria-label="A"> <polygon points="50,0 0,100 100,100" fill="#16a34a"></polygon><polygon points="50,6 6,96 94,96" fill="#fefce8"></polygon><polygon points="50,10 10,94 90,94" fill="#f97373"></polygon><ellipse cx="50" cy="45" rx="3" ry="7" fill="#111827"></ellipse><ellipse cx="37" cy="60" rx="3" ry="7" fill="#111827" transform="rotate(-15 37 60)"></ellipse><ellipse cx="63" cy="60" rx="3" ry="7" fill="#111827" transform="rotate(15 63 60)"></ellipse><ellipse cx="30" cy="75" rx="3" ry="7" fill="#111827" transform="rotate(-20 30 75)"></ellipse><ellipse cx="50" cy="70" rx="3" ry="7" fill="#111827" transform="rotate(10 50 70)"></ellipse><ellipse cx="70" cy="75" rx="3" ry="7" fill="#111827" transform="rotate(20 70 75)"></ellipse><ellipse cx="42" cy="50" rx="2.5" ry="6" fill="#111827" transform="rotate(-25 42 50)"></ellipse><ellipse cx="58" cy="50" rx="2.5" ry="6" fill="#111827" transform="rotate(25 58 50)"></ellipse><ellipse cx="45" cy="82" rx="3" ry="6" fill="#111827" transform="rotate(-10 45 82)"></ellipse><ellipse cx="55" cy="82" rx="3" ry="6" fill="#111827" transform="rotate(10 55 82)"></ellipse> </svg> <span class="letter">D</span> <span class="letter bold">G</span> <svg class="watermelon-a" viewbox="0 0 100 100" role="img" aria-label="A"> <polygon points="50,0 0,100 100,100" fill="#16a34a"></polygon><polygon points="50,6 6,96 94,96" fill="#fefce8"></polygon><polygon points="50,10 10,94 90,94" fill="#f97373"></polygon><ellipse cx="50" cy="45" rx="3" ry="7" fill="#111827"></ellipse><ellipse cx="37" cy="60" rx="3" ry="7" fill="#111827" transform="rotate(-15 37 60)"></ellipse><ellipse cx="63" cy="60" rx="3" ry="7" fill="#111827" transform="rotate(15 63 60)"></ellipse><ellipse cx="30" cy="75" rx="3" ry="7" fill="#111827" transform="rotate(-20 30 75)"></ellipse><ellipse cx="50" cy="70" rx="3" ry="7" fill="#111827" transform="rotate(10 50 70)"></ellipse><ellipse cx="70" cy="75" rx="3" ry="7" fill="#111827" transform="rotate(20 70 75)"></ellipse><ellipse cx="42" cy="50" rx="2.5" ry="6" fill="#111827" transform="rotate(-25 42 50)"></ellipse><ellipse cx="58" cy="50" rx="2.5" ry="6" fill="#111827" transform="rotate(25 58 50)"></ellipse><ellipse cx="45" cy="82" rx="3" ry="6" fill="#111827" transform="rotate(-10 45 82)"></ellipse><ellipse cx="55" cy="82" rx="3" ry="6" fill="#111827" transform="rotate(10 55 82)"></ellipse> </svg> <span class="letter bold">D</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">Courses </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">Contact </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title watermelon-name">Research</h1> </header> <article> <p>Currently, my main research looks at how AI can solve challenges in Economics. For example, by analyzing data to predict economic risks or detect early signs of financial instability or financial stress.</p> <p>My previous research and publications focused on using AI in various areas like <strong>medical imaging</strong>, <strong>healthcare systems</strong>, <strong>Internet of Things</strong>, and <strong>smart networks</strong>. I worked on projects such as detecting diseases from medical scans, improving healthcare, and optimizing smart networks using Federated Learning.</p> <p>If youâ€™re interested in working together or need support with research, feel free to <a href="/contact">contact me</a>.</p> <hr> <h1 id="-publications"><a href="https://scholar.google.com/citations?user=Vmjcp8gAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">ðŸ“š Publications</a></h1> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10618889" class="col-sm-8"> <div class="title">Communication-Efficient and Privacy-Preserving Federated Learning via Joint Knowledge Distillation and Differential Privacy in Bandwidth-Constrained Networks</div> <div class="author"> Gad Gad, <em>Eyad Gad</em>, Zubair Md Fadlullah, Mostafa M. Fouda, and Nei Kato </div> <div class="periodical"> <em>IEEE Transactions on Vehicular Technology</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TVT.2024.3423718" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10577749" class="col-sm-8"> <div class="title">A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under Non-IID Challenges</div> <div class="author"> <em>Eyad Gad</em>, Zubair Md Fadlullah, and Mostafa M. Fouda </div> <div class="periodical"> <em>In 2024 International Conference on Smart Applications, Communications and Networking (SmartNets)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/SmartNets61466.2024.10577749" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10.1007/978-3-031-49333-1_18" class="col-sm-8"> <div class="title">Advancing Brain Tumor Segmentation viaÂ Attention-Based 3D U-Net Architecture andÂ Digital Image Processing</div> <div class="author"> <em>Eyad Gad</em>, Seif Soliman, and M. Saeed Darweesh </div> <div class="periodical"> <em>In Model and Data Engineering</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>In the realm of medical diagnostics, rapid advancements in Artificial Intelligence (AI) have significantly yielded remarkable improvements in brain tumor segmentation. Encoder-Decoder architectures, such as U-Net, have played a transformative role by effectively extracting meaningful representations in 3D brain tumor segmentation from Magnetic resonance imaging (MRI) scans. However, standard U-Net models encounter challenges in accurately delineating tumor regions, especially when dealing with irregular shapes and ambiguous boundaries. Additionally, training robust segmentation models on high-resolution MRI data, such as the BraTS datasets, necessitates high computational resources and often faces challenges associated with class imbalance. This study proposes the integration of the attention mechanism into the 3D U-Net model, enabling the model to capture intricate details and prioritize informative regions during the segmentation process. Additionally, a tumor detection algorithm based on digital image processing techniques is utilized to address the issue of imbalanced training data and mitigate bias. This study aims to enhance the performance of brain tumor segmentation, ultimately improving the reliability of diagnosis. The proposed model is thoroughly evaluated and assessed on the BraTS 2020 dataset using various performance metrics to accomplish this goal. The obtained results indicate that the model outperformed related studies, exhibiting dice of 0.975, specificity of 0.988, and sensitivity of 0.995, indicating the efficacy of the proposed model in improving brain tumor segmentation, offering valuable insights for reliable diagnosis in clinical settings.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10.1007/978-3-031-48593-0_23" class="col-sm-8"> <div class="title">A Novel Approach toÂ Breast Cancer Segmentation Using U-Net Model withÂ Attention Mechanisms andÂ FedProx</div> <div class="author"> <em>Eyad Gad</em>, Mustafa Abou Khatwa, Mustafa A. Elattar, and Sahar Selim </div> <div class="periodical"> <em>In Medical Image Understanding and Analysis</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Breast cancer is a leading cause of death among women worldwide, emphasizing the need for early detection and accurate diagnosis. As such Ultrasound Imaging, a reliable and cost-effective tool, is used for this purpose, however the sensitive nature of medical data makes it challenging to develop accurate and private artificial intelligence models. A solution is Federated Learning as it is a promising technique for distributed machine learning on sensitive medical data while preserving patient privacy. However, training on non-Independent and non-Identically Distributed (non-IID) local datasets can impact the accuracy and generalization of the trained model, which is crucial for accurate tumour boundary delineation in BC segmentation. This study aims to tackle this challenge by applying the Federated Proximal (FedProx) method to non-IID Ultrasonic Breast Cancer Imaging datasets. Moreover, we focus on enhancing tumour segmentation accuracy by incorporating a modified U-Net model with attention mechanisms. Our approach resulted in a global model with 96% accuracy, demonstrating the effectiveness of our method in enhancing tumour segmentation accuracy while preserving patient privacy. Our findings suggest that FedProx has the potential to be a promising approach for training precise machine learning models on non-IID local medical datasets.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10.1007/978-3-031-21595-7_3" class="col-sm-8"> <div class="title">A Novel Diagnostic Model for Early Detection of Alzheimerâ€™s Disease Based on Clinical and Neuroimaging Features</div> <div class="author"> <em>Eyad Gad</em>, Aya Gamal, Mustafa Elattar, and Sahar Selim </div> <div class="periodical"> <em>In Model and Data Engineering</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Alzheimerâ€™s Disease (AD) is a dangerous disease that is known for its characteristics of eroding memory and destroying the brain. The classification of Alzheimerâ€™s disease is an important topic that has recently been addressed by many studies using Machine Learning (ML) and Deep Learning (DL) methods. Most research papers tackling early diagnosis of AD use these methods as a feature extractor for neuroimaging data. In our research paper, the proposed algorithm is to optimize the performance of the prediction of early diagnosis from the multimodal dataset by a multi-step framework that uses a Deep Neural Network (DNN) as an optimization technique to extract features and train these features by Random Forest (RF) classifier. The results of the proposed algorithm showed that using only demographic and clinical data results in a balanced accuracy of 88% and an area under the curve (AUC) of 94.6. Ultimately, combining clinical and neuroimaging features, prediction results improved further to a balanced accuracy of 92% and an AUC of 97%. This study successfully outperformed other studies for both clinical and the combination of clinical and neuroimaging data, proving that multimodal data is efficient in the early diagnosis of AD.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="electronics11111785" class="col-sm-8"> <div class="title">Deep Learning-Based Context-Aware Video Content Analysis on IoT Devices</div> <div class="author"> Gad Gad, <em>Eyad Gad</em>, Korhan Cengiz, Zubair Fadlullah, and Bassem Mokhtar </div> <div class="periodical"> <em>Electronics</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/electronics11111785" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Integrating machine learning with the Internet of Things (IoT) enables many useful applications. For IoT applications that incorporate video content analysis (VCA), deep learning models are usually used due to their capacity to encode the high-dimensional spatial and temporal representations of videos. However, limited energy and computation resources present a major challenge. Video captioning is one type of VCA that describes a video with a sentence or a set of sentences. This work proposes an IoT-based deep learning-based framework for video captioning that can (1) Mine large open-domain video-to-text datasets to extract video-caption pairs that belong to a particular domain. (2) Preprocess the selected video-caption pairs including reducing the complexity of the captionsâ€™ language model to improve performance. (3) Propose two deep learning models: A transformer-based model and an LSTM-based model. Hyperparameter tuning is performed to select the best hyperparameters. Models are evaluated in terms of accuracy and inference time on different platforms. The presented framework generates captions in standard sentence templates to facilitate extracting information in later stages of the analysis. The two developed deep learning models offer a trade-off between accuracy and speed. While the transformer-based model yields a high accuracy of 97%, the LSTM-based model achieves near real-time inference.</p> </div> </div> </div> </li></ol> </div> <hr> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 EYAD GAD. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script defer src="/assets/js/scroll-header.js?01362796b870350f628b95b8b3c50d57"></script> </body> </html>